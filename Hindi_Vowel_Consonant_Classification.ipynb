{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arka57/Hindi-Vowel-Consonant-Classification/blob/main/Hindi_Vowel_Consonant_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36h1XGpd86fI"
      },
      "outputs": [],
      "source": [
        "#importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3xWmaHUAkSq",
        "outputId": "f8402cce-08b6-48cc-bdbb-c4b3afb45abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjbAbIP-Q0E8",
        "outputId": "e7e5357a-e7b1-45fe-e01a-26ac5f99ae42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/DL/project/Hindi_Vowel_Consonant\n"
          ]
        }
      ],
      "source": [
        "cd MyDrive/DL/project/Hindi_Vowel_Consonant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4sWjd6HRBNw",
        "outputId": "16469fb7-f23c-4d72-fce9-69e1a37b0c0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzfLZPgT8qgh"
      },
      "outputs": [],
      "source": [
        "!unzip train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-uPpnY0Rg7M"
      },
      "outputs": [],
      "source": [
        "!unzip test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUhyOh-H-OHL",
        "outputId": "ccc1b3b2-ab4f-4f6d-e7fc-780b04a7907e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtest\u001b[0m/  test.zip  \u001b[01;34mtrain\u001b[0m/  train.zip\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VveuQcY--Xca"
      },
      "outputs": [],
      "source": [
        "#Code for making the image data in tensor form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykerTJgC-Xvj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            label=torch.stack([z1,z2])\n",
        "\n",
        "            return image_data, label\n",
        "\n",
        "        else:\n",
        "            return image_data, file_name\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        return classes_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ1emsf8-asr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sHpTv14-hjA"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjDeJZg7-_Wl"
      },
      "outputs": [],
      "source": [
        "#Splitting of data into train,validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsYm-R6_-lEi"
      },
      "outputs": [],
      "source": [
        "full_data = VowelConsonantDataset(\"./train\",train=True,transform=transform)\n",
        "train_size = int(0.9 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "\n",
        "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=60, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyThQghj-o6h"
      },
      "outputs": [],
      "source": [
        "test_data = VowelConsonantDataset(\"./test\",train=False,transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FZmgOAC_FjK",
        "outputId": "df96035f-4c01-47cc-df53-a946c62bd501"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Subset"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr1iTOQnW1wu",
        "outputId": "568e3743-3929-4406-e793-492719a0fad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 64, 64])\n",
            "torch.Size([3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "dataiter=iter(train_loader)\n",
        "images,labels=dataiter.next()\n",
        "print(images.shape)\n",
        "print(images[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtEb0giaXXpZ"
      },
      "outputs": [],
      "source": [
        "#image dimesnion: 3X64X64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks6VCZq2_MyR"
      },
      "outputs": [],
      "source": [
        "#First Model Applied--LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g2NoaEb_cdy"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet,self).__init__()\n",
        "        self.cnn_model=nn.Sequential(\n",
        "            nn.Conv2d(3,6,(5,5)),               #(3,64,64)--->(6,60,60)\n",
        "            nn.AvgPool2d(2,stride=2),           #(6,60,60)--->(6,30,30)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(6,16,(5,5)),              #(6,30,30)--->(16,26,26)\n",
        "            nn.AvgPool2d(2,stride=2),           #(16,26,26)--->(16,13,13)\n",
        "            nn.ReLU()\n",
        "\n",
        "        )\n",
        "        self.vowel_model=nn.Sequential(         #Vowel part--fully connected layers\n",
        "            nn.Linear(2704,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84,10)\n",
        "        )    \n",
        "        self.consonant_model=nn.Sequential(     #Consonant part--fully connected layers\n",
        "            nn.Linear(2704,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84,10)\n",
        "        )  \n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.cnn_model(x)\n",
        "        x=x.view(x.size(0),-1)\n",
        "        v1=self.vowel_model(x)\n",
        "        c1=self.consonant_model(x)\n",
        "        return v1,c1                        #returning vowel,consonant\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3IrjNi_ly98"
      },
      "outputs": [],
      "source": [
        "#Learning Algo\n",
        "\n",
        "\n",
        "for j,data in enumerate(train_loader,0):\n",
        "    if(j==1):\n",
        "        images,labels=data\n",
        "        break    \n",
        "print(data[0])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdEnAj0Tnxfx",
        "outputId": "dc4985c9-bc69-471c-b91d-e39c7fe34b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "print(data[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "987WzJydo063",
        "outputId": "ef7b86af-43b4-411f-915e-d15452907d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 64, 64])\n",
            "torch.Size([2, 10])\n"
          ]
        }
      ],
      "source": [
        "print(images[0].shape)\n",
        "print(labels[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oHPIItupDxQ"
      },
      "outputs": [],
      "source": [
        "for _,i in enumerate(labels,0):\n",
        "    vowel,consonant=i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWtpT5rTpDia"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReuEKLOCpSWZ",
        "outputId": "4c8c732c-6c28-4c72-ba92-0723a8b744db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "print(vowel.shape)\n",
        "print(consonant.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WnzE5OApj4E",
        "outputId": "c45d619a-967f-49c2-e2f7-e442334678c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "print(vowel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c58vuKs3szVJ"
      },
      "outputs": [],
      "source": [
        "#instantiating network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O1U8BsCBUJ8",
        "outputId": "5ec27010-d8a3-4ae7-b19a-ef2011f4e1b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMasLWozs3UB"
      },
      "outputs": [],
      "source": [
        "net=LeNet().to(device)\n",
        "opt=optim.Adam(net.parameters(),weight_decay=0.01)\n",
        "loss_fn=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QpaqImDtNoM"
      },
      "outputs": [],
      "source": [
        "#Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thUEaZk_tQs1"
      },
      "outputs": [],
      "source": [
        "def evaluation(dataloader):\n",
        "    total=0\n",
        "    correct=0\n",
        "    for i in dataloader:\n",
        "        images,labels=i\n",
        "        images,labels=images.to(device),labels.to(device)\n",
        "        for j in labels:\n",
        "            vowel_label,consonant_label=j\n",
        "        vowel,consonant=net.forward(images)\n",
        "        _,vowel_pred=torch.max(vowel,1)\n",
        "        _,consonant_pred=torch.max(consonant,1)\n",
        "        total+=labels.size(0)\n",
        "        correct+=((vowel_pred==vowel_label) and (consonant_pred==consonant_label)).sum().item()\n",
        "    return (correct/total)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1VmLPpZqzSE"
      },
      "outputs": [],
      "source": [
        "#Learning Algo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3dItTOo5q11l",
        "outputId": "ccd50d61-b579-42e3-bde3-1b178bc77c20"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7a5d3ff241f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d/%d, Training Accuaracy 0.2%f, Test Accuracy 0.2%f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
          ]
        }
      ],
      "source": [
        "loss_epoch=[]\n",
        "epochs=3\n",
        "\n",
        "for i in range(epochs):\n",
        "    for _,data in enumerate(train_loader,0):\n",
        "        input,labels=data\n",
        "        input,labels=input.to(device),labels.to(device)\n",
        "        #print(input.shape)\n",
        "        #print(labels.shape)\n",
        "        \n",
        "        \n",
        "        vowel_label,consonant_label=labels[:,0,:],labels[:,1,:]\n",
        "        \n",
        "        vowel,consonant=net.forward(input)\n",
        "        #print(vowel_label.shape)\n",
        "        #print(consonant_label.shape)\n",
        "        #print(vowel.shape)\n",
        "        #print(consonant.shape)\n",
        "        lossV=loss_fn(vowel,vowel_label)\n",
        "        lossC=loss_fn(consonant,consonant_label)\n",
        "        loss=lossV+lossC\n",
        "        loss.backward()\n",
        "\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        del vowel,consonant,labels,input\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    loss_epoch.append(loss.item())\n",
        "    print('Epoch %d/%d, Training Accuaracy 0.2%f, Test Accuracy 0.2%f' % (i,epochs,evaluate(train_loader),evaluate(test_loader))) \n",
        "\n",
        "plt.plot(loss_epoch)\n",
        "plt.show()           \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM80NeNzpCK5k6ZCnLUXAIi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}